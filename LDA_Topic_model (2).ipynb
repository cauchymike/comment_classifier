{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmi1cCkKQu-q"
      },
      "outputs": [],
      "source": [
        "!pip install pandas gensim nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyLDAvis\n"
      ],
      "metadata": {
        "id": "2IvzCeabanr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-openai"
      ],
      "metadata": {
        "id": "n3TPb8VJ-tqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5VU4N5df77Y",
        "outputId": "4bb7aba0-690d-46ba-9c4c-ef78c28efb1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.0)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.59)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain\n",
            "Successfully installed dataclasses-json-0.6.6 langchain-0.2.0 langchain-text-splitters-0.2.0 marshmallow-3.21.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.models import TfidfModel\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from typing import List, Tuple, Dict\n",
        "import pyLDAvis\n",
        "from pyLDAvis import gensim\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"ipykernel.ipkernel\")\n",
        "from openai import OpenAI\n",
        "import json\n",
        "from google.colab import userdata #we need this to get our openai secret key from the enviroment variables\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTb_Tld7SDJB",
        "outputId": "da1508b5-444d-4122-b323-2559ff0c4b84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Load usernames and comments data from CSV files.\"\"\"\n",
        "    usernames_df = pd.read_csv('usernames.csv')\n",
        "    comments_df = pd.read_csv('user_comments.csv')\n",
        "    return usernames_df, comments_df"
      ],
      "metadata": {
        "id": "12Gs0TscSuau"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usernames_df, comments_df = load_data()"
      ],
      "metadata": {
        "id": "DKUORy22T2-F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text: str) -> list:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    filtered_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and token.isalpha()]\n",
        "    return filtered_tokens\n"
      ],
      "metadata": {
        "id": "hlB1pcqJTSO3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_dictionary_corpus_with_tfidf(df: pd.DataFrame) -> tuple:\n",
        "    comments = df['comments'].apply(preprocess_text)\n",
        "    dictionary = corpora.Dictionary(comments)\n",
        "    corpus = [dictionary.doc2bow(text) for text in comments]\n",
        "\n",
        "    # Create TF-IDF model\n",
        "    tfidf_model = TfidfModel(corpus)\n",
        "    tfidf_corpus = tfidf_model[corpus]\n",
        "\n",
        "    return dictionary, tfidf_corpus\n"
      ],
      "metadata": {
        "id": "dXrDV6zcT4c_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lda_model(corpus, dictionary, num_topics=3) -> LdaModel:\n",
        "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10, random_state=42)\n",
        "    return lda_model\n"
      ],
      "metadata": {
        "id": "nroEWP1cUC_Y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_topics_to_documents(df: pd.DataFrame, dictionary, lda_model) -> pd.DataFrame:\n",
        "    def get_dominant_topic(text):\n",
        "        bow = dictionary.doc2bow(preprocess_text(text))\n",
        "        topic_distribution = lda_model.get_document_topics(bow)\n",
        "        return max(topic_distribution, key=lambda x: x[1])[0]\n",
        "\n",
        "    df['topic'] = df['comments'].apply(get_dominant_topic)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "CczsfWETUG6E"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_top_words(lda_model, num_words=10):\n",
        "    for i in range(lda_model.num_topics):\n",
        "        topic = lda_model.show_topic(i, num_words)\n",
        "        words = [word for word, _ in topic]\n",
        "        print(f\"Topic #{i}: {' '.join(words)}\")\n"
      ],
      "metadata": {
        "id": "WvgrYlFoUNWm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load data\n",
        "    usernames_df, comments_df = load_data()\n",
        "\n",
        "    # Assuming comments are in 'comments' column, adjust this if necessary\n",
        "    comments = comments_df['comments']\n",
        "\n",
        "    # Number of topics\n",
        "    num_topics = 3\n",
        "\n",
        "    # Create dictionary and corpus with TF-IDF\n",
        "    dictionary, tfidf_corpus = create_dictionary_corpus_with_tfidf(comments_df)\n",
        "\n",
        "    # Build and fit the LDA model\n",
        "    lda_model = build_lda_model(tfidf_corpus, dictionary, num_topics=num_topics)\n",
        "\n",
        "    # Assign topics to documents\n",
        "    df_with_topics = assign_topics_to_documents(comments_df, dictionary, lda_model)\n",
        "\n",
        "    # Print the DataFrame with assigned topics\n",
        "    print(df_with_topics)\n",
        "\n",
        "    # Print the top words for each topic\n",
        "    print_top_words(lda_model, num_words=10)\n",
        "\n",
        "    return (df_with_topics, lda_model, dictionary, tfidf_corpus)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0chu6YsqUTQK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_with_topics, lda_model, dictionary, tfidf_corpus = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiHzt_DqZ1PQ",
        "outputId": "83d58e7c-494a-40c1-ab73-9165615dccb2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  username                                           comments  \\\n",
            "0           LoveAGoodTwist  Female, Kentucky.  4 years out. Work equine on...   \n",
            "1               wahznooski  As a woman of reproductive age, fuck Texas|As ...   \n",
            "2     Churro_The_fish_Girl  what makes you want to become a vet?|what make...   \n",
            "3                 abarthch  I see of course there are changing variables, ...   \n",
            "4               VoodooKing  I have 412+ and faced issues because wireguard...   \n",
            "...                    ...                                                ...   \n",
            "3271            B1u3Chips_  I’m looking into applying for veterinary nursi...   \n",
            "3272           Daktari2018  Good for you for sticking to standards of care...   \n",
            "3273               Sheepb1  Yes feel free to ask someone to double check, ...   \n",
            "3274               Elyrath  Same! Helps massively. Errors can still occur,...   \n",
            "3275         Real_Use_3216  It’s no different than undergrad. School is sc...   \n",
            "\n",
            "      topic  \n",
            "0         2  \n",
            "1         2  \n",
            "2         2  \n",
            "3         2  \n",
            "4         2  \n",
            "...     ...  \n",
            "3271      2  \n",
            "3272      2  \n",
            "3273      2  \n",
            "3274      2  \n",
            "3275      2  \n",
            "\n",
            "[3276 rows x 3 columns]\n",
            "Topic #0: node myst http mysterium vpn network ip traffic app port\n",
            "Topic #1: midline wear congratulation glove triad csu mandala unionizing hf avsag\n",
            "Topic #2: vet school year like work get would time animal clinic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def visualize_lda_model(lda_model, corpus, dictionary):\n",
        "    vis_data = gensim.prepare(lda_model, corpus, dictionary)\n",
        "    pyLDAvis.display(vis_data)\n",
        "    return pyLDAvis.display(vis_data)"
      ],
      "metadata": {
        "id": "i-oR4tSvackG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the LDA model\n",
        "%matplotlib inline\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = visualize_lda_model(lda_model, tfidf_corpus, dictionary)"
      ],
      "metadata": {
        "id": "IUQLWS9tbIg2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "fP8h2MfhdLpi",
        "outputId": "ccd9ec19-cca4-45ce-d593-ef610d2abfdb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el4471342035928763042902254250\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el4471342035928763042902254250_data = {\"mdsDat\": {\"x\": [0.11637605323248656, -0.06467011553339819, -0.05170593769908838], \"y\": [-0.001357746679503046, -0.017603334973363267, 0.018961081652866304], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [81.50169517699905, 13.016609959166614, 5.481694863834335]}, \"tinfo\": {\"Term\": [\"node\", \"http\", \"myst\", \"mysterium\", \"vpn\", \"network\", \"ip\", \"running\", \"traffic\", \"connection\", \"app\", \"link\", \"update\", \"port\", \"token\", \"user\", \"vet\", \"using\", \"access\", \"run\", \"wallet\", \"midline\", \"use\", \"docker\", \"address\", \"dashboard\", \"pi\", \"connect\", \"residential\", \"window\", \"vet\", \"school\", \"year\", \"animal\", \"clinic\", \"time\", \"job\", \"like\", \"would\", \"tech\", \"practice\", \"people\", \"make\", \"work\", \"lot\", \"good\", \"experience\", \"know\", \"thing\", \"want\", \"much\", \"feel\", \"going\", \"take\", \"also\", \"go\", \"veterinary\", \"doctor\", \"first\", \"student\", \"get\", \"day\", \"really\", \"one\", \"think\", \"need\", \"thank\", \"ip\", \"traffic\", \"port\", \"wallet\", \"myst\", \"node\", \"residential\", \"docker\", \"server\", \"dashboard\", \"router\", \"vpn\", \"polygon\", \"token\", \"runner\", \"network\", \"mysterium\", \"matic\", \"isp\", \"metamask\", \"reward\", \"device\", \"io\", \"install\", \"github\", \"hosting\", \"linux\", \"mainnet\", \"setup\", \"container\", \"app\", \"transaction\", \"pi\", \"user\", \"http\", \"connection\", \"android\", \"update\", \"link\", \"connect\", \"running\", \"access\", \"address\", \"using\", \"use\", \"hf\", \"unionizing\", \"avsag\", \"thc\", \"danskos\", \"triad\", \"adorable\", \"urethrostomies\", \"hons\", \"mandala\", \"bookkeeper\", \"anaesthesia\", \"bracelet\", \"egypt\", \"vial\", \"emt\", \"peel\", \"hydrogen\", \"triggering\", \"carrot\", \"soylent\", \"bout\", \"wing\", \"iam\", \"spicy\", \"traz\", \"pebkac\", \"busted\", \"basketball\", \"practised\", \"ital\", \"glove\", \"proudly\", \"yupp\", \"congratulation\", \"midline\", \"csu\", \"creation\", \"wear\", \"italy\", \"bird\", \"flank\", \"cop\", \"spray\"], \"Freq\": [16.0, 16.0, 10.0, 8.0, 6.0, 6.0, 5.0, 8.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0, 4.0, 54.0, 8.0, 5.0, 7.0, 3.0, 3.0, 14.0, 2.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 54.4718306744443, 42.47290761374433, 40.93080550571541, 30.840187038447137, 30.437498189941753, 32.04543820380878, 28.54619601455807, 36.87373944951888, 35.490300189586115, 25.58548820805277, 24.867712544517072, 27.31017701192109, 27.002670728419268, 35.713799384076665, 23.75725158066557, 25.746906205065404, 22.791307728437083, 29.713935164878176, 25.292048499968395, 25.604197751475635, 28.001187634171302, 22.357906111216845, 22.12569747970798, 21.81542055925704, 28.64474464532093, 25.23286528548571, 19.95635070067894, 19.553761663939422, 21.93658171766674, 18.877937918133913, 35.64409979543493, 28.243232887295793, 24.134479824411823, 29.62208080599859, 27.10194557582345, 24.792585260883094, 25.407072955669676, 5.1190551791912835, 4.389824162584608, 3.39525567358873, 2.8066828101365093, 9.786915669344602, 14.81767527202176, 2.4708428351113345, 2.5740263928872325, 2.3062980595074984, 2.5345547868227096, 1.9689509817990747, 5.834999725858392, 1.8488664911698836, 3.295410910997679, 1.8589775602065768, 5.421294198888546, 7.119041317631398, 1.573011181809055, 1.728477336854291, 1.4199406975103386, 1.9846351838091576, 1.8592183228491455, 1.2521461759182222, 1.4737433150932917, 1.219313957018694, 1.1973425794034933, 1.1326686764946399, 1.3579981863159247, 1.6715897417810253, 1.1856491006469485, 3.655401357943542, 1.3941312720387997, 2.2761724964344747, 2.815668533693753, 8.585392450036869, 3.371615860332303, 1.9737524924904872, 2.8467887543049692, 2.873535120242852, 2.101707255552646, 3.154160745591975, 2.2783061041904813, 2.0397079892375807, 2.1672632677095867, 2.0611259700710325, 0.32910188795286893, 0.3308071290084023, 0.31993292216602076, 0.30294729643287177, 0.2729274031158892, 0.3570314279099606, 0.25624320610574663, 0.2578103924010358, 0.2598708546338397, 0.34472409633259404, 0.266590802471984, 0.25499067239123613, 0.2552370933382576, 0.31335597718369845, 0.2330410650892067, 0.316119387287098, 0.22664838602875295, 0.2610004383009225, 0.28623615979125, 0.2307227955023061, 0.21881782222324078, 0.3077833509225153, 0.20350947067792952, 0.20831518552889855, 0.18757553227680207, 0.18757553227680207, 0.18248764576485607, 0.21753768334392776, 0.19972673841738442, 0.1860004897946744, 0.23361013948500256, 0.40270900542642507, 0.2314478361856132, 0.2158285793014959, 0.42424742887956124, 0.615491294025874, 0.35426286715736316, 0.24039897002211172, 0.44324322567525537, 0.31700917640416115, 0.2725950126252321, 0.28198687420293356, 0.24593693067801872, 0.23627308299281044], \"Total\": [16.0, 16.0, 10.0, 8.0, 6.0, 6.0, 5.0, 8.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0, 4.0, 54.0, 8.0, 5.0, 7.0, 3.0, 3.0, 14.0, 2.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 54.66542951361832, 42.66807240241969, 41.1247914985249, 31.02914854942169, 30.628532168192834, 32.254141365034585, 28.734795453371547, 37.13538309126287, 35.74347539534038, 25.779262364988636, 25.05641050560252, 27.517464021082652, 27.2098838295994, 36.00031999261549, 23.952730030324496, 25.960135815825172, 22.980831516702242, 29.961687642225453, 25.50499272663209, 25.82409908032949, 28.242981779141253, 22.55110864449487, 22.3218316094183, 22.008853429898206, 28.912761663744536, 25.471499604417005, 20.14604232538383, 19.74326629326716, 22.150995956117406, 19.06563625040996, 36.093141744780986, 28.56697670828544, 24.374652358705927, 30.0198313783672, 27.486220362983133, 25.185696149079785, 26.133639727444457, 5.543187579877876, 4.828759603236933, 3.763805920215934, 3.1116567530913533, 10.871662933795703, 16.495366780905332, 2.7721018120157206, 2.909002883054079, 2.6205337205682673, 2.902358080043185, 2.261981653444638, 6.723859458224152, 2.1490976852686874, 3.8422795411634425, 2.179184776403298, 6.3763008154948055, 8.404262125248398, 1.86403439178662, 2.051783024558063, 1.7103736183168368, 2.3947629848562704, 2.255965825935903, 1.5453944226275675, 1.832182431052726, 1.5250109421384166, 1.5042336974930386, 1.4336040390902283, 1.7287396515215212, 2.1328289462573182, 1.512841374474493, 4.854600349344398, 1.795907499934518, 3.187984007460129, 4.1014002429484115, 16.23016250550751, 5.598238888149487, 2.8016334100471227, 4.84488453299975, 4.927245055145011, 3.4853411274233688, 8.57774939704153, 5.477103576984912, 4.018648244712522, 8.077950151431473, 14.634484019046996, 0.6770648459012152, 0.6811369880251936, 0.6742079055806296, 0.6643144297820892, 0.6379035685460246, 0.8382297243957706, 0.6027056734941447, 0.610048924453302, 0.6156697851460249, 0.822243236944072, 0.6584388971931957, 0.6309490893429213, 0.6320223574193922, 0.7867491824262438, 0.5892483567196507, 0.8032627990972192, 0.5818825490975383, 0.6730072594951548, 0.747103698910213, 0.6047967381731583, 0.5777724709455889, 0.821102795446002, 0.5534356953840721, 0.5776741860240764, 0.5434533750973716, 0.5434533750973716, 0.5294272647965744, 0.6367900502029068, 0.5852469798028521, 0.5468818943401246, 0.6932129528695667, 1.2569358470148768, 0.7039959154345083, 0.6489394465457954, 1.8719005242429618, 3.799548015073075, 1.7361730451448232, 0.7928695813189708, 3.513623283621945, 1.569938329313564, 1.9595956324233663, 3.930295990308755, 1.4383913788653262, 0.9235190915335947], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.6035, -5.8523, -5.8893, -6.1724, -6.1855, -6.134, -6.2497, -5.9937, -6.0319, -6.3592, -6.3876, -6.2939, -6.3053, -6.0257, -6.4333, -6.3529, -6.4748, -6.2096, -6.3707, -6.3584, -6.2689, -6.494, -6.5044, -6.5186, -6.2462, -6.373, -6.6076, -6.628, -6.513, -6.6632, -6.0276, -6.2603, -6.4175, -6.2127, -6.3016, -6.3906, -6.3662, -6.1338, -6.2875, -6.5444, -6.7348, -5.4857, -5.071, -6.8622, -6.8213, -6.9311, -6.8368, -7.0893, -6.0029, -7.1522, -6.5743, -7.1468, -6.0765, -5.804, -7.3138, -7.2196, -7.4162, -7.0814, -7.1466, -7.5419, -7.379, -7.5685, -7.5867, -7.6422, -7.4608, -7.253, -7.5965, -6.4706, -7.4345, -6.9443, -6.7316, -5.6167, -6.5514, -7.0869, -6.7206, -6.7112, -7.024, -6.6181, -6.9434, -7.054, -6.9933, -7.0435, -8.0134, -8.0082, -8.0416, -8.0962, -8.2005, -7.9319, -8.2636, -8.2575, -8.2496, -7.967, -8.224, -8.2685, -8.2675, -8.0624, -8.3585, -8.0536, -8.3863, -8.2452, -8.1529, -8.3685, -8.4215, -8.0803, -8.494, -8.4707, -8.5756, -8.5756, -8.6031, -8.4274, -8.5128, -8.584, -8.3561, -7.8115, -8.3654, -8.4353, -7.7594, -7.3873, -7.9397, -8.3274, -7.7156, -8.0508, -8.2017, -8.1679, -8.3047, -8.3447], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.201, 0.2, 0.1998, 0.1984, 0.1983, 0.1981, 0.198, 0.1975, 0.1974, 0.197, 0.197, 0.197, 0.1969, 0.1966, 0.1964, 0.1963, 0.1963, 0.1962, 0.1962, 0.196, 0.1959, 0.1959, 0.1957, 0.1957, 0.1952, 0.1951, 0.1951, 0.1949, 0.1948, 0.1947, 0.192, 0.1931, 0.1946, 0.1912, 0.1905, 0.1888, 0.1764, 1.9593, 1.9436, 1.9359, 1.9358, 1.9338, 1.9317, 1.9239, 1.9166, 1.9112, 1.9034, 1.9002, 1.8972, 1.8885, 1.8854, 1.88, 1.8767, 1.873, 1.8692, 1.8675, 1.8528, 1.8511, 1.8455, 1.8285, 1.8212, 1.8152, 1.8108, 1.8033, 1.7976, 1.7953, 1.7952, 1.7552, 1.7857, 1.7021, 1.6628, 1.4021, 1.5319, 1.6887, 1.5072, 1.4997, 1.5331, 1.0385, 1.1618, 1.3608, 0.7233, 0.0788, 2.1824, 2.1815, 2.1583, 2.1186, 2.0548, 2.0503, 2.0485, 2.0424, 2.0412, 2.0345, 1.9996, 1.9978, 1.997, 1.9832, 1.9761, 1.9712, 1.9609, 1.9565, 1.9444, 1.9401, 1.9328, 1.9225, 1.9033, 1.8838, 1.84, 1.84, 1.8386, 1.8297, 1.8287, 1.8253, 1.8161, 1.7655, 1.7913, 1.8029, 1.4194, 1.0835, 1.3144, 1.7104, 0.8335, 1.3039, 0.9312, 0.2691, 1.1376, 1.5406]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 3, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1], \"Freq\": [0.5477347575835819, 0.3651565050557213, 0.4976797863887368, 0.4976797863887368, 1.0030172951747067, 0.35693463549293564, 0.7138692709858713, 0.9990606075002263, 0.20599018004335773, 0.8239607201734309, 1.0206187271027274, 0.9794788674579205, 0.5342164217857795, 0.2869159612905026, 0.5738319225810052, 0.35725520828231494, 0.5358828124234724, 0.6610078339160734, 0.6952210745234368, 0.5759794525070425, 1.0336422719953846, 0.9801527227023293, 0.8865382520456782, 1.031281205486598, 1.0130036085680714, 1.0008341074727356, 0.9755617937378256, 0.9931833333175385, 1.0177350535082141, 0.9974194060068363, 0.6557329999204922, 0.7955855522578347, 0.9814891305286462, 0.9855822042272504, 1.00153559228109, 0.6647903192612981, 0.49290942079509653, 0.5545230983944835, 0.5457971777545237, 0.6470839970418316, 0.9020080825246323, 0.9747619392799993, 0.6369676956911025, 1.009229386966015, 1.001278711607705, 0.9963543370232602, 0.4059063386570569, 0.6088595079855854, 0.69754267756849, 1.0019734689789288, 0.5784561018889495, 0.9922864856419901, 1.0729415770505506, 0.5846675774759031, 0.789567598066609, 0.26318919935553636, 0.9913967377438629, 0.09198224835424168, 0.9198224835424168, 0.11898724541155882, 0.8329107178809118, 0.9926269201382957, 0.1568307438648343, 0.7841537193241715, 0.12124616727620481, 0.9093462545715361, 0.9993393907474947, 0.9811950686776153, 0.31367785963164263, 0.6273557192632853, 0.9306231232341369, 0.7970655404643942, 0.9977486597455806, 0.9846294276040367, 0.7214742226749996, 0.8351557179760053, 0.8841804693483337, 0.6718915656963947, 0.2687566262785579, 0.9177743997004977, 0.5829034830190426, 0.34974208981142557, 0.9843425689326006, 0.763203306373137, 0.9377217068952454, 1.0828146479780956, 0.9965573532638572, 0.9995977332519204, 1.0085626047745708, 0.9566214373785081, 0.038264857495140324, 0.9802002403198187, 0.9823103956614585, 0.9921206594167753, 0.7807865013100009, 0.82837008438329, 0.5568215512416212, 0.41280653571359394, 0.6192098035703909, 0.8883128358389889, 0.1366635132059983, 0.24381916925062663, 0.7314575077518799, 0.7427626919605038, 0.2475875639868346, 0.9878272334171901, 0.9927508180998995, 0.14872410796404592, 0.8923446477842755, 0.9641166227668186, 1.0068115026635913, 0.8538194785946184, 0.6874107656590192, 0.45827384377267943, 0.9999911113952444, 0.9791996892546911, 0.9969655408823319], \"Term\": [\"access\", \"access\", \"address\", \"address\", \"also\", \"android\", \"android\", \"animal\", \"app\", \"app\", \"bird\", \"clinic\", \"congratulation\", \"connect\", \"connect\", \"connection\", \"connection\", \"container\", \"cop\", \"csu\", \"dashboard\", \"day\", \"device\", \"docker\", \"doctor\", \"experience\", \"feel\", \"first\", \"flank\", \"get\", \"github\", \"glove\", \"go\", \"going\", \"good\", \"hosting\", \"http\", \"http\", \"install\", \"io\", \"ip\", \"isp\", \"italy\", \"job\", \"know\", \"like\", \"link\", \"link\", \"linux\", \"lot\", \"mainnet\", \"make\", \"matic\", \"metamask\", \"midline\", \"midline\", \"much\", \"myst\", \"myst\", \"mysterium\", \"mysterium\", \"need\", \"network\", \"network\", \"node\", \"node\", \"one\", \"people\", \"pi\", \"pi\", \"polygon\", \"port\", \"practice\", \"really\", \"residential\", \"reward\", \"router\", \"run\", \"run\", \"runner\", \"running\", \"running\", \"school\", \"server\", \"setup\", \"spray\", \"student\", \"take\", \"tech\", \"thank\", \"thank\", \"thing\", \"think\", \"time\", \"token\", \"traffic\", \"transaction\", \"update\", \"update\", \"use\", \"use\", \"user\", \"user\", \"using\", \"using\", \"vet\", \"veterinary\", \"vpn\", \"vpn\", \"wallet\", \"want\", \"wear\", \"window\", \"window\", \"work\", \"would\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el4471342035928763042902254250\", ldavis_el4471342035928763042902254250_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el4471342035928763042902254250\", ldavis_el4471342035928763042902254250_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el4471342035928763042902254250\", ldavis_el4471342035928763042902254250_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#was not used, just tested to see how it fared\n",
        "#df_with_topics.to_csv(\"training_data.csv\", index = False) w"
      ],
      "metadata": {
        "id": "GgZbeC86wBSS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_topics(lda_model: LdaModel, num_topics: int, words_per_topic: int) -> List[List[str]]:\n",
        "    \"\"\"\n",
        "    Extracts the top words for each topic from the LDA model.\n",
        "\n",
        "    Parameters:\n",
        "        lda_model (LdaModel): The trained LDA model.\n",
        "        dictionary (Dictionary): The dictionary used for LDA model training.\n",
        "        num_topics (int): The number of topics to extract.\n",
        "        words_per_topic (int): The number of words per topic.\n",
        "\n",
        "    Returns:\n",
        "        List[List[str]]: A list of lists containing the top words for each topic.\n",
        "    \"\"\"\n",
        "    topic_words = []\n",
        "    for topic_id in range(num_topics):\n",
        "        top_words = lda_model.show_topic(topic_id, topn=words_per_topic)\n",
        "        topic_words.append([word for word, _ in top_words])\n",
        "    return topic_words"
      ],
      "metadata": {
        "id": "sYtYVDGu9ABq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_topics_to_documents(lda_model: LdaModel, corpus: List[List[Tuple[int, int]]], num_topics: int) -> List[int]:\n",
        "    document_topics = []\n",
        "    for doc_bow in corpus:\n",
        "        topic_probs = lda_model.get_document_topics(doc_bow)\n",
        "        most_likely_topic = max(topic_probs, key=lambda x: x[1])[0]\n",
        "        document_topics.append(most_likely_topic)\n",
        "    return document_topics"
      ],
      "metadata": {
        "id": "ChEdVMWlort4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the most likely topic to each document using the lda model\n",
        "# Extract top words for each topic\n",
        "\n",
        "num_topics = 3\n",
        "words_per_topic = 20\n",
        "top_words_per_topic = extract_topics(lda_model, num_topics, words_per_topic)\n",
        "\n",
        "# Assign the most likely topic to each document using the lda model\n",
        "document_topics = assign_topics_to_documents(lda_model, tfidf_corpus, num_topics)\n"
      ],
      "metadata": {
        "id": "KUS2-uUHo8OY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_topics"
      ],
      "metadata": {
        "id": "avwo0knIrBZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "def generate_detailed_description(comment: str, topic_words: List[str]) -> str:\n",
        "    \"\"\"\n",
        "    Generates a detailed description of the topic discussed in the comment using the OpenAI API.\n",
        "\n",
        "    Parameters:\n",
        "        comment (str): The comment to describe.\n",
        "        topic_words (List[str]): The list of topic words.\n",
        "\n",
        "    Returns:\n",
        "        str: A detailed description generated by the language model.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    I have a comment that reads as follows:\n",
        "    \"{comment}\"\n",
        "\n",
        "    Based on the comment above, the main topic has the following keywords:\n",
        "    {', '.join(topic_words)}\n",
        "\n",
        "    Please provide a detailed description of the topic discussed in the comment, and categorize it under one of the following labels:\n",
        "    1. Medical Doctor\n",
        "    This label should only include practicing doctors and or consultants to doctors/clinics.\n",
        "    Medical school students, nurses or medical professionals who aren’t doctors should go into the “Other” label (C) instead\n",
        "    2. Veterinarian\n",
        "    This label should only include practicing vets and/or consultants to vets/clinics.\n",
        "    Veterinarian students or veterinarian technicians should go into the “Other” label (C) instead\n",
        "    3. Other\n",
        "    Anyone who does not fit within the Medical Doctor, or a Veterinarian label.\n",
        "\n",
        "    Make sure the response is in the following format and in JSON:\n",
        "    {{\n",
        "        \"topic\": \"<topic label>\",\n",
        "        \"description\": \"<detailed topic description>\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "      response = client.chat.completions.create(\n",
        "          model=\"gpt-3.5-turbo\",\n",
        "          response_format={ \"type\": \"json_object\" },\n",
        "          messages=[\n",
        "              {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "              {\"role\": \"user\", \"content\": prompt}\n",
        "          ],\n",
        "          seed= 1111)\n",
        "    except Exception as e:\n",
        "\n",
        "      # Truncate comment and topic words if they are too long\n",
        "      comment = comment[:60000]  # Limit the comment to 80000 characters\n",
        "      topic_words = topic_words[:20]\n",
        "      prompt = f\"\"\"\n",
        "        I have a comment that reads as follows:\n",
        "        \"{comment}\"\n",
        "\n",
        "        Based on the comment above, the main topic has the following keywords:\n",
        "        {', '.join(topic_words)}\n",
        "\n",
        "        Please provide a detailed description of the topic discussed in the comment, and categorize it under one of the following labels:\n",
        "        1. Medical Doctor\n",
        "        This label should only include practicing doctors and or consultants to doctors/clinics.\n",
        "        Medical school students, nurses or medical professionals who aren’t doctors should go into the “Other” label (C) instead\n",
        "        2. Veterinarian\n",
        "        This label should only include practicing vets and/or consultants to vets/clinics.\n",
        "        Veterinarian students or veterinarian technicians should go into the “Other” label (C) instead\n",
        "        3. Other\n",
        "        Anyone who does not fit within the Medical Doctor, or a Veterinarian label.\n",
        "\n",
        "        Make sure the response is in the following format and in JSON:\n",
        "        {{\n",
        "            \"topic\": \"<topic label>\",\n",
        "            \"description\": \"<detailed topic description>\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "      response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        response_format={ \"type\": \"json_object\" },\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        seed= 1111\n",
        "    )\n",
        "    for choice in response.choices:\n",
        "      # Extract topic and description from content\n",
        "      content = choice.message.content\n",
        "      # content = response.choices[0].message['content']\n",
        "\n",
        "    # Parse the JSON response\n",
        "    try:\n",
        "        response_json = json.loads(content)\n",
        "        topic_label = response_json[\"topic\"]\n",
        "        description = response_json[\"description\"]\n",
        "    except (json.JSONDecodeError, KeyError):\n",
        "        topic_label = \"Unknown\"\n",
        "        description = \"Could not generate a detailed description.\"\n",
        "\n",
        "    return topic_label, description\n",
        "\n"
      ],
      "metadata": {
        "id": "rC5uAFUHsqPJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Clean the 'comments' column and get the label using llm\n",
        "comments_df['topic_id'] = document_topics\n",
        "comments_df['comments'] = comments_df['comments'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
        "comments_df['topic_words'] = comments_df['topic_id'].apply(lambda x: top_words_per_topic[x])\n",
        "comments_df['detailed_description'] = comments_df.apply(\n",
        "    lambda row: generate_detailed_description(row['comments'], row['topic_words']), axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "gnLogc1fsjvV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df.to_csv(\"training_data.csv\", index = False)"
      ],
      "metadata": {
        "id": "KdgWRjMGVRom"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}